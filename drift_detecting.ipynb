{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7858d1fa-f0a2-4ec0-9452-4713f0caf282",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import shapiro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aef1250b-e3f9-4c4c-8e33-2e24bbcfbb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Колмогоров-Смирнов\n",
    "def ks_2samp(data1, data2):\n",
    "    # Сортируем данные в порядке возрастания\n",
    "    data1 = np.sort(data1)\n",
    "    data2 = np.sort(data2)\n",
    "    \n",
    "    # Вычисляем кумулятивные функции распределения\n",
    "    n1 = data1.shape[0]\n",
    "    n2 = data2.shape[0]\n",
    "    n = n1 + n2\n",
    "    cdf1 = np.searchsorted(data1, data1, side='right') / n1\n",
    "    cdf2 = np.searchsorted(data2, data1, side='right') / n2\n",
    "    \n",
    "    # Вычисляем максимальное абсолютное отклонение\n",
    "    max_diff = np.max(np.abs(cdf1 - cdf2))\n",
    "    \n",
    "    # Вычисляем статистику KS\n",
    "    ks_statistic = max_diff * np.sqrt(n / (n1 * n2 / n))\n",
    "    \n",
    "    return ks_statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "712548ee-f33e-424f-910f-5e873c823abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Неравенство Чебышева\n",
    "def chebyshev_inequality(data, k):\n",
    "    mean = np.mean(data)\n",
    "    std = np.std(data)\n",
    "    \n",
    "    # Вычисляем вероятность с помощью неравенства Чебышева\n",
    "    probability = 1 - 1 / (k**2)\n",
    "    \n",
    "    # Вычисляем интервал с помощью неравенства Чебышева\n",
    "    interval = [mean - k * std, mean + k * std]\n",
    "    \n",
    "    return probability, interval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1c000ce-cc2b-43cb-ae4b-6ad3c09645a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PSI\n",
    "def calculate_psi(actual, expected, bins=10):\n",
    "    # Разбиваем данные на корзины (bins) на основе ожидаемого распределения\n",
    "    expected_bins = np.histogram(expected, bins=bins)[0]\n",
    "    expected_bins = np.where(expected_bins == 0, 0.0001, expected_bins)  # Избегаем деления на ноль\n",
    "    \n",
    "    # Разбиваем фактические данные на корзины на основе ожидаемого распределения\n",
    "    actual_bins = np.histogram(actual, bins=bins)[0]\n",
    "    \n",
    "    # Вычисляем относительные частоты для фактических и ожидаемых данных\n",
    "    actual_freq = actual_bins / actual.size\n",
    "    expected_freq = expected_bins / expected.size\n",
    "    \n",
    "    # Вычисляем показатель PSI\n",
    "    psi = np.sum((expected_freq - actual_freq) * np.log(expected_freq / actual_freq))\n",
    "    \n",
    "    return psi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76101971-3325-4c22-baef-628fed9b00e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# расстояние Вассерштейна\n",
    "def wasserstein_distance(data1, data2):\n",
    "    sorted_data1 = np.sort(data1)\n",
    "    sorted_data2 = np.sort(data2)\n",
    "    n1 = sorted_data1.shape[0]\n",
    "    n2 = sorted_data2.shape[0]\n",
    "    cdf1 = np.linspace(1/n1, 1, n1)\n",
    "    cdf2 = np.linspace(1/n2, 1, n2)\n",
    "    wasserstein_dist = np.sum(np.abs(cdf1 - cdf2)) / n1\n",
    "    return wasserstein_dist\n",
    "\n",
    "def wasserstein_stat_test(data1, data2):\n",
    "    # Вычисляем расстояние Вассерштейна между распределениями\n",
    "    wasserstein_dist = wasserstein_distance(data1, data2)\n",
    "    \n",
    "    # Вычисляем статистику теста\n",
    "    stat_test = wasserstein_dist\n",
    "    \n",
    "    return stat_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfff2d2c-d77f-41c6-b3f5-8c6960630f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shapiro_wilk_test(ref_samples, curr_samples):\n",
    "    _, p_value = shapiro(curr_samples)\n",
    "\n",
    "    threshold = 0.05\n",
    "    drift_detected = p_value < threshold\n",
    "\n",
    "    return drift_detected, p_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81232da5-a840-48e4-9773-11b733d13453",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cramers_v(confusion_matrix):\n",
    "    chi2 = np.sum(confusion_matrix)\n",
    "    n = confusion_matrix.shape[0]\n",
    "    m = confusion_matrix.shape[1]\n",
    "    \n",
    "    chi2corr = chi2 / (n * min(m - 1, n - 1))\n",
    "    phi2 = chi2corr / min(m - 1, n - 1)\n",
    "    v = np.sqrt(phi2)\n",
    "    \n",
    "    return v"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
